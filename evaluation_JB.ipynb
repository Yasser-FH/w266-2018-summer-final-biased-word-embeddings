{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import debiaswe as dwe\n",
    "import debiaswe.we as we\n",
    "from debiaswe.we import WordEmbedding\n",
    "from debiaswe.debias import debias\n",
    "import vector_math as vm \n",
    "\n",
    "# Standard python helper libraries.\n",
    "import os, sys, re, json, time\n",
    "import itertools, collections\n",
    "\n",
    "# NumPy and SciPy for matrix ops\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Reading data from ./embeddings/final/GNews.txt\n",
      "26423 words of dimension 300\n",
      "*** Reading data from ./embeddings/final/GNews_gender_debiased.txt\n",
      "26423 words of dimension 300\n",
      "*** Reading data from ./embeddings/final/GNews_political_debiased.txt\n",
      "26423 words of dimension 300\n",
      "*** Reading data from ./embeddings/final/RANE.txt\n",
      "50000 words of dimension 300\n",
      "50000 words of dimension 300\n",
      "*** Reading data from ./embeddings/final/RANE_gender_debiased.txt\n",
      "50000 words of dimension 300\n",
      "*** Reading data from ./embeddings/final/RANE_political_debiased.txt\n",
      "50000 words of dimension 300\n"
     ]
    }
   ],
   "source": [
    "# load subset of word embedding trained on Google News text\n",
    "E_gn = WordEmbedding(\"./embeddings/final/GNews.txt\")\n",
    "E_gn_db_g = WordEmbedding(\"./embeddings/final/GNews_gender_debiased.txt\")\n",
    "E_gn_db_p = WordEmbedding(\"./embeddings/final/GNews_political_debiased.txt\")\n",
    "E_rane = WordEmbedding(\"./embeddings/final/RANE.txt\")\n",
    "E_rane_db_g = WordEmbedding(\"./embeddings/final/RANE_gender_debiased.txt\")\n",
    "E_rane_db_p = WordEmbedding(\"./embeddings/final/RANE_political_debiased.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Word Similarity Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "File #                     Embeddings      RG (53/65)    WS (318/353)\n",
      "========================================================================\n",
      "     1                          GNews          0.7618          0.6857 \n",
      "\n",
      "     2          GNews_gender_debiased          0.7641          0.6827 \n",
      "\n",
      "     3       GNews_political_debiased          0.7570          0.6803 \n",
      "\n",
      "     4                           RANE          0.6052          0.6159 \n",
      "\n",
      "     5           RANE_gender_debiased          0.5964          0.6136 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# adapted from Faruqui and Dyer, Community Evaluation and Exchange of Word Vectors at wordvectors.org\n",
    "# RG = Rubenstein and Goodenough, 1965; WS = Finkelstein et. al, 2002 -- benchmarks used in Bolukbasi et al.\n",
    "\n",
    "%run 'evaluation/all_wordsim_jb.py' 'embeddings/final' 'evaluation/data/word-sim/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mikolov Analogies Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./evaluation/data/analogies_2000.json', \"r\") as f:\n",
    "    analogies = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_analogies(analogy_list,e):\n",
    "    num_analogies = 0\n",
    "    correct = 0  \n",
    "    num_missing = 0\n",
    "    #keep_analogies = []\n",
    "    t0 = time.time()\n",
    "    print_freq = 500\n",
    "    \n",
    "    for i,wds in enumerate(analogy_list):\n",
    "        # we'll get KeyError if a word can't be found\n",
    "        #print(wds)\n",
    "        try:\n",
    "            \n",
    "            # generate \"d\" in a:b::c:d analogies, given a, b, and c\n",
    "            d = vm.show_analogy(e,wds[0],wds[1],wds[2],5)[0] # needs to be at least 2 \n",
    "\n",
    "            # keep track of how many analogies were computed\n",
    "            num_analogies += 1\n",
    "            #keep_analogies.append(wds)\n",
    "\n",
    "            if d == wds[3]:\n",
    "                correct += 1\n",
    "                \n",
    "        except:\n",
    "            #bad_analogies.append(wds)\n",
    "            num_missing += 1\n",
    "        \n",
    "        #if i % print_freq  == 0:\n",
    "            #print(\"Completed {:d} analogies in {:s}\".format(i, utils.pretty_timedelta(since=t0)))\n",
    "    \n",
    "    try: # if we're running on a subset, we may actually not be able to do _any_ analogies\n",
    "        score = correct / num_analogies\n",
    "    except:\n",
    "        score = 0\n",
    "                \n",
    "    print(\"Computed {:d}/{:d} analogies correctly in {:s}, accuracy: {:.4f}\".format(correct,num_analogies,utils.pretty_timedelta(since=t0),score))\n",
    "    \n",
    "    #return keep_analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_to_eval = [E_gn, E_gn_db_g, E_gn_db_p, E_rane, E_rane_db_g, E_rane_db_p]\n",
    "embedding_names = [\"Google News\", \"Google News Debiased, Gender\", \"Google News Debiased, Political\", \n",
    "                   \"RANE\", \"RANE Debiased, Gender\", \"RANE Debiased, Political\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File # 1: Google News\n"
     ]
    }
   ],
   "source": [
    "for i,e in enumerate(embeddings_to_eval):\n",
    "    print(\"File # {:d}: {:s}\".format(i+1,embedding_names[i]))\n",
    "    compare_analogies(analogies,e) \n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
